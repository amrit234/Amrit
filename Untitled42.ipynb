{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOm/h42fxdizgpIPVEzILx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrit234/Amrit/blob/main/Untitled42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EDKLZyzETsP",
        "outputId": "897a79a7-8bd2-4956-ab43-a7c7571c4fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date        Open        High         Low       Close   Adj Close  \\\n",
            "0  2020-09-08  113.949997  118.989998  112.680000  112.820000  110.816940   \n",
            "1  2020-09-09  117.260002  119.139999  115.260002  117.320000  115.237038   \n",
            "2  2020-09-10  120.360001  120.500000  112.500000  113.489998  111.475044   \n",
            "3  2020-09-11  114.570000  115.230003  110.000000  112.000000  110.011497   \n",
            "4  2020-09-14  114.720001  115.930000  112.800003  115.360001  113.311844   \n",
            "\n",
            "      Volume  \n",
            "0  231366600  \n",
            "1  176940500  \n",
            "2  182274400  \n",
            "3  180860300  \n",
            "4  140150100  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "df = pd.read_csv(\"/content/AAPL.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiD_zM6sE_7w",
        "outputId": "989aeeed-7b30-422d-e53c-15dfa7d5cc62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252 entries, 0 to 251\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Date       252 non-null    object \n",
            " 1   Open       252 non-null    float64\n",
            " 2   High       252 non-null    float64\n",
            " 3   Low        252 non-null    float64\n",
            " 4   Close      252 non-null    float64\n",
            " 5   Adj Close  252 non-null    float64\n",
            " 6   Volume     252 non-null    int64  \n",
            "dtypes: float64(5), int64(1), object(1)\n",
            "memory usage: 13.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wtbiNt4FEmO",
        "outputId": "ed59081a-7941-43cd-d228-e1d968b24f7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date         0\n",
              "Open         0\n",
              "High         0\n",
              "Low          0\n",
              "Close        0\n",
              "Adj Close    0\n",
              "Volume       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "XMkVxoq7FHyh",
        "outputId": "d9ff160e-c52a-49ec-c9d9-720126209880"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Open        High         Low       Close   Adj Close  \\\n",
              "count  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
              "mean   129.063334  130.507104  127.582420  129.070952  127.178481   \n",
              "std     11.192471   11.113959   11.405234   11.359554   11.387850   \n",
              "min    104.540001  110.190002  103.099998  106.839996  104.943100   \n",
              "25%    120.500000  122.042498  118.990000  120.679998  118.815855   \n",
              "50%    127.820000  128.715004  126.399998  127.619999  125.767231   \n",
              "75%    135.737496  136.552505  133.710003  135.025005  133.069050   \n",
              "max    154.970001  157.259995  154.389999  156.690002  154.897980   \n",
              "\n",
              "             Volume  \n",
              "count  2.520000e+02  \n",
              "mean   1.027298e+08  \n",
              "std    3.861931e+07  \n",
              "min    4.639770e+07  \n",
              "25%    7.631650e+07  \n",
              "50%    9.366130e+07  \n",
              "75%    1.168119e+08  \n",
              "max    2.871049e+08  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6bc127a-66e1-4694-9ed5-a48472d2ce6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>2.520000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>129.063334</td>\n",
              "      <td>130.507104</td>\n",
              "      <td>127.582420</td>\n",
              "      <td>129.070952</td>\n",
              "      <td>127.178481</td>\n",
              "      <td>1.027298e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.192471</td>\n",
              "      <td>11.113959</td>\n",
              "      <td>11.405234</td>\n",
              "      <td>11.359554</td>\n",
              "      <td>11.387850</td>\n",
              "      <td>3.861931e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>104.540001</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>103.099998</td>\n",
              "      <td>106.839996</td>\n",
              "      <td>104.943100</td>\n",
              "      <td>4.639770e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>120.500000</td>\n",
              "      <td>122.042498</td>\n",
              "      <td>118.990000</td>\n",
              "      <td>120.679998</td>\n",
              "      <td>118.815855</td>\n",
              "      <td>7.631650e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>127.820000</td>\n",
              "      <td>128.715004</td>\n",
              "      <td>126.399998</td>\n",
              "      <td>127.619999</td>\n",
              "      <td>125.767231</td>\n",
              "      <td>9.366130e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>135.737496</td>\n",
              "      <td>136.552505</td>\n",
              "      <td>133.710003</td>\n",
              "      <td>135.025005</td>\n",
              "      <td>133.069050</td>\n",
              "      <td>1.168119e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>154.970001</td>\n",
              "      <td>157.259995</td>\n",
              "      <td>154.389999</td>\n",
              "      <td>156.690002</td>\n",
              "      <td>154.897980</td>\n",
              "      <td>2.871049e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6bc127a-66e1-4694-9ed5-a48472d2ce6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6bc127a-66e1-4694-9ed5-a48472d2ce6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6bc127a-66e1-4694-9ed5-a48472d2ce6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0cb13ef-54f3-4b04-9887-98f82a9a7c70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0cb13ef-54f3-4b04-9887-98f82a9a7c70')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0cb13ef-54f3-4b04-9887-98f82a9a7c70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figure = go.Figure(data=[go.Candlestick(x=df[\"Date\"],\n",
        "                                        open = df[\"Open\"],\n",
        "                                        high = df[\"High\"],\n",
        "                                        low = df[\"Low\"],\n",
        "                                        close = df[\"Close\"])])\n",
        "figure.update_layout(title = \"Apple Stock Price Analysis\", xaxis_rangeslider_visible=True)\n",
        "figure.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dvLgGQ_aFKhl",
        "outputId": "7ed44062-2637-4ae2-ad70-33f084664b5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f21fc384-bfbf-4fc9-880a-5520dac3763d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f21fc384-bfbf-4fc9-880a-5520dac3763d\")) {                    Plotly.newPlot(                        \"f21fc384-bfbf-4fc9-880a-5520dac3763d\",                        [{\"close\":[112.82,117.32,113.489998,112.0,115.360001,115.540001,112.129997,110.339996,106.839996,110.080002,111.809998,107.120003,108.220001,112.279999,114.959999,114.089996,115.809998,116.790001,113.019997,116.5,113.160004,115.080002,114.970001,116.970001,124.400002,121.099998,121.190002,120.709999,119.019997,115.980003,117.510002,116.870003,115.75,115.040001,115.050003,116.599998,111.199997,115.32,108.860001,108.769997,110.440002,114.949997,119.029999,118.690002,116.32,115.970001,119.489998,119.209999,119.260002,120.300003,119.389999,118.029999,118.639999,117.339996,113.849998,115.169998,116.029999,116.589996,119.050003,122.720001,123.080002,122.940002,122.25,123.75,124.379997,121.779999,123.239998,122.410004,121.779999,127.879997,127.809998,128.699997,126.660004,128.229996,131.880005,130.960007,131.970001,136.690002,134.869995,133.720001,132.690002,129.410004,131.009995,126.599998,130.919998,132.050003,128.979996,128.800003,130.889999,128.910004,127.139999,127.830002,132.029999,136.869995,139.070007,142.919998,143.160004,142.059998,137.089996,131.960007,134.139999,134.990005,133.940002,137.389999,136.759995,136.910004,136.009995,135.389999,135.130005,135.369995,133.190002,130.839996,129.710007,129.869995,126.0,125.860001,125.349998,120.989998,121.260002,127.790001,125.120003,122.059998,120.129997,121.419998,116.360001,121.089996,119.980003,121.959999,121.029999,123.989998,125.57,124.760002,120.529999,119.989998,123.389999,122.540001,120.089996,120.589996,121.209999,121.389999,119.900002,122.150002,123.0,125.900002,126.209999,127.900002,130.360001,133.0,131.240005,134.429993,132.029999,134.5,134.160004,134.839996,133.110001,133.5,131.940002,134.320007,134.720001,134.389999,133.580002,133.479996,131.460007,132.539993,127.849998,128.100006,129.740005,130.210007,126.849998,125.910004,122.769997,124.970001,127.449997,126.269997,124.849998,124.690002,127.309998,125.43,127.099998,126.900002,126.849998,125.279999,124.610001,124.279999,125.059998,123.540001,125.889999,125.900002,126.739998,127.129997,126.110001,127.349998,130.479996,129.639999,130.149994,131.789993,130.460007,132.300003,133.979996,133.699997,133.410004,133.110001,134.779999,136.330002,136.960007,137.270004,139.960007,142.020004,144.570007,143.240005,145.110001,144.5,145.639999,149.149994,148.479996,146.389999,142.449997,146.149994,145.399994,146.800003,148.559998,148.990005,146.770004,144.979996,145.639999,145.860001,145.520004,147.360001,146.949997,147.059998,146.139999,146.089996,145.600006,145.860001,148.889999,149.100006,151.119995,150.190002,146.360001,146.699997,148.190002,149.710007,149.619995,148.360001,147.539993,148.600006,153.119995,151.830002,152.509995,153.649994,154.300003,156.690002],\"high\":[118.989998,119.139999,120.5,115.230003,115.93,118.830002,116.0,112.199997,110.879997,110.190002,112.860001,112.110001,110.25,112.440002,115.32,115.309998,117.260002,117.720001,115.370003,116.650002,116.120003,115.550003,116.400002,117.0,125.18,125.389999,123.029999,121.199997,121.550003,120.419998,118.980003,118.709999,118.040001,116.550003,116.550003,117.279999,115.43,116.93,111.989998,110.68,111.489998,115.589996,119.620003,119.199997,121.989998,117.589996,119.629997,120.529999,119.669998,120.989998,120.669998,119.82,119.059998,118.769997,117.620003,115.849998,116.75,117.489998,120.970001,123.470001,123.370003,123.779999,122.860001,124.57,124.980003,125.949997,123.870003,122.760002,123.349998,127.900002,128.369995,129.580002,129.100006,128.309998,134.410004,132.429993,133.460007,137.339996,138.789993,135.990005,134.740005,133.610001,131.740005,131.050003,131.630005,132.630005,130.169998,129.690002,131.449997,131.0,130.220001,128.710007,132.490005,139.669998,139.850006,145.089996,144.300003,144.300003,141.990005,136.740005,135.380005,136.309998,135.770004,137.399994,137.419998,136.960007,137.880005,136.990005,136.389999,135.529999,136.009995,132.220001,130.0,130.710007,129.720001,126.709999,125.559998,126.459999,124.849998,127.93,128.720001,125.709999,123.599998,121.940002,121.0,122.059998,122.169998,123.209999,121.169998,124.0,127.220001,125.860001,123.18,121.43,123.870003,124.239998,122.900002,121.660004,121.480003,122.580002,120.400002,123.519997,124.18,126.160004,127.129997,127.919998,130.389999,133.039993,132.850006,134.660004,135.0,135.0,134.669998,135.470001,135.529999,133.75,134.149994,135.119995,135.059998,135.410004,135.020004,137.070007,133.559998,134.070007,131.490005,130.449997,129.75,131.259995,129.539993,126.269997,124.639999,126.150002,127.889999,126.93,126.989998,124.919998,127.720001,128.0,127.940002,128.320007,127.389999,127.639999,125.800003,125.349998,125.239998,124.849998,126.160004,126.32,128.460007,127.75,128.190002,127.440002,130.539993,130.600006,130.889999,132.550003,131.509995,132.410004,134.080002,134.320007,134.639999,133.889999,135.25,136.490005,137.410004,137.330002,140.0,143.149994,144.889999,144.059998,145.649994,146.320007,147.460007,149.570007,150.0,149.759995,144.070007,147.100006,146.130005,148.199997,148.720001,149.830002,149.210007,146.970001,146.550003,146.330002,146.949997,148.039993,147.789993,147.839996,147.110001,146.699997,147.710007,146.720001,149.050003,149.440002,151.190002,151.679993,150.720001,148.0,148.5,150.190002,150.860001,150.320007,149.119995,148.75,153.490005,152.800003,154.979996,154.720001,154.630005,157.259995],\"low\":[112.68,115.260002,112.5,110.0,112.800003,113.610001,112.040001,108.709999,106.089996,103.099998,109.160004,106.769997,105.0,107.669998,112.779999,113.57,113.620003,115.830002,112.220001,113.550003,112.25,114.129997,114.589996,114.919998,119.279999,119.650002,119.620003,118.150002,118.809998,115.660004,115.629997,116.449997,114.589996,114.279999,112.879997,114.540001,111.099998,112.199997,107.720001,107.32,108.730003,112.349998,116.870003,116.129997,116.050003,114.129997,116.440002,118.57,117.870003,118.150002,118.959999,118.0,116.809998,117.290001,113.75,112.589996,115.169998,116.220001,116.809998,120.010002,120.889999,122.209999,121.519997,122.25,123.089996,121.0,120.150002,120.550003,121.540001,124.129997,126.559998,128.039993,126.120003,123.449997,129.649994,130.779999,131.100006,133.509995,134.339996,133.399994,131.720001,126.760002,128.429993,126.379997,127.860001,130.229996,128.5,126.860001,128.490005,128.759995,127.0,126.940002,128.550003,133.589996,135.020004,136.539993,141.369995,140.410004,136.699997,130.210007,130.929993,134.610001,133.610001,134.589996,135.860001,134.919998,135.850006,134.399994,133.770004,133.690002,132.789993,129.470001,127.410004,128.800003,125.599998,118.389999,122.230003,120.540001,121.199997,122.790001,125.010002,121.839996,118.620003,117.57,116.209999,118.790001,119.449997,121.260002,119.160004,120.419998,124.720001,122.339996,120.32,119.68,120.260002,122.139999,120.07,119.0,118.919998,120.730003,118.860001,121.150002,122.489998,123.07,125.650002,125.139999,128.520004,129.470001,130.630005,131.929993,131.660004,133.639999,133.279999,133.339996,131.809998,131.300003,131.410004,132.160004,133.559998,134.110001,133.080002,132.449997,131.070007,131.830002,126.699997,127.970001,127.129997,129.479996,126.809998,122.769997,122.25,124.260002,125.849998,125.169998,124.779999,122.860001,125.099998,125.209999,125.940002,126.32,126.419998,125.080002,124.550003,123.940002,124.050003,123.129997,123.849998,124.830002,126.209999,126.519997,125.940002,126.099998,127.07,129.389999,128.460007,129.649994,130.240005,129.210007,131.619995,133.229996,132.929993,132.809998,133.350006,134.350006,135.869995,135.759995,137.75,140.070007,142.660004,140.669998,142.649994,144.0,143.630005,147.679993,147.089996,145.880005,141.669998,142.960007,144.630005,145.809998,146.919998,147.699997,145.550003,142.539993,144.580002,144.110001,145.25,145.179993,146.279999,146.169998,145.630005,145.520004,145.300003,145.529999,145.839996,148.270004,146.470001,149.089996,146.149994,144.5,146.779999,147.889999,149.149994,147.800003,147.509995,146.830002,148.610001,151.289993,152.339996,152.399994,153.089996,154.389999],\"open\":[113.949997,117.260002,120.360001,114.57,114.720001,118.330002,115.230003,109.720001,110.400002,104.540001,112.68,111.620003,105.169998,108.43,115.010002,114.550003,113.790001,117.639999,112.889999,113.910004,115.699997,114.620003,116.25,115.279999,120.059998,125.269997,121.0,118.720001,121.279999,119.959999,116.199997,116.669998,117.449997,116.389999,114.010002,115.489998,115.050003,112.370003,111.059998,109.110001,109.660004,114.139999,117.949997,118.32,120.5,115.550003,117.190002,119.620003,119.440002,118.919998,119.550003,118.610001,117.589996,118.639999,117.18,113.910004,115.550003,116.57,116.970001,121.010002,122.019997,123.519997,122.599998,122.309998,124.370003,124.529999,120.5,122.43,122.599998,124.339996,127.410004,128.899994,128.960007,125.019997,131.610001,132.160004,131.320007,133.990005,138.050003,135.580002,134.080002,133.520004,128.889999,127.720001,128.360001,132.429993,129.190002,128.5,128.759995,130.800003,128.779999,127.779999,128.660004,133.800003,136.279999,143.070007,143.600006,143.429993,139.520004,135.830002,133.75,135.729996,135.759995,136.300003,137.350006,136.029999,136.619995,136.479996,135.899994,134.350006,135.490005,131.25,129.199997,130.240005,128.009995,123.760002,124.940002,124.68,122.589996,123.75,128.410004,124.809998,121.75,120.980003,120.93,119.029999,121.690002,122.540001,120.400002,121.410004,125.699997,124.050003,122.879997,119.900002,120.330002,123.330002,122.82,119.540001,120.349998,121.650002,120.110001,121.650002,123.660004,123.870003,126.5,125.830002,128.949997,129.800003,132.520004,132.440002,134.940002,133.820007,134.300003,133.509995,135.020004,132.360001,133.039993,132.160004,134.830002,135.009995,134.309998,136.470001,131.779999,132.039993,131.190002,129.199997,127.889999,130.850006,129.410004,123.5,123.400002,124.580002,126.25,126.82,126.559998,123.160004,125.230003,127.82,126.010002,127.82,126.959999,126.440002,125.57,125.080002,124.279999,124.68,124.07,126.169998,126.599998,127.209999,127.019997,126.529999,127.82,129.940002,130.369995,129.800003,130.710007,130.300003,132.130005,133.770004,134.449997,133.460007,133.410004,134.800003,136.169998,136.600006,137.899994,140.070007,143.539993,141.580002,142.75,146.210007,144.029999,148.100006,149.240005,148.460007,143.75,143.460007,145.529999,145.940002,147.550003,148.270004,149.119995,144.809998,144.690002,144.380005,146.360001,145.809998,147.270004,146.979996,146.350006,146.199997,146.440002,146.050003,146.190002,148.970001,148.539993,150.229996,149.800003,145.029999,147.440002,148.309998,149.449997,149.809998,148.350006,147.479996,149.0,152.660004,152.830002,153.869995,153.759995,154.970001],\"x\":[\"2020-09-08\",\"2020-09-09\",\"2020-09-10\",\"2020-09-11\",\"2020-09-14\",\"2020-09-15\",\"2020-09-16\",\"2020-09-17\",\"2020-09-18\",\"2020-09-21\",\"2020-09-22\",\"2020-09-23\",\"2020-09-24\",\"2020-09-25\",\"2020-09-28\",\"2020-09-29\",\"2020-09-30\",\"2020-10-01\",\"2020-10-02\",\"2020-10-05\",\"2020-10-06\",\"2020-10-07\",\"2020-10-08\",\"2020-10-09\",\"2020-10-12\",\"2020-10-13\",\"2020-10-14\",\"2020-10-15\",\"2020-10-16\",\"2020-10-19\",\"2020-10-20\",\"2020-10-21\",\"2020-10-22\",\"2020-10-23\",\"2020-10-26\",\"2020-10-27\",\"2020-10-28\",\"2020-10-29\",\"2020-10-30\",\"2020-11-02\",\"2020-11-03\",\"2020-11-04\",\"2020-11-05\",\"2020-11-06\",\"2020-11-09\",\"2020-11-10\",\"2020-11-11\",\"2020-11-12\",\"2020-11-13\",\"2020-11-16\",\"2020-11-17\",\"2020-11-18\",\"2020-11-19\",\"2020-11-20\",\"2020-11-23\",\"2020-11-24\",\"2020-11-25\",\"2020-11-27\",\"2020-11-30\",\"2020-12-01\",\"2020-12-02\",\"2020-12-03\",\"2020-12-04\",\"2020-12-07\",\"2020-12-08\",\"2020-12-09\",\"2020-12-10\",\"2020-12-11\",\"2020-12-14\",\"2020-12-15\",\"2020-12-16\",\"2020-12-17\",\"2020-12-18\",\"2020-12-21\",\"2020-12-22\",\"2020-12-23\",\"2020-12-24\",\"2020-12-28\",\"2020-12-29\",\"2020-12-30\",\"2020-12-31\",\"2021-01-04\",\"2021-01-05\",\"2021-01-06\",\"2021-01-07\",\"2021-01-08\",\"2021-01-11\",\"2021-01-12\",\"2021-01-13\",\"2021-01-14\",\"2021-01-15\",\"2021-01-19\",\"2021-01-20\",\"2021-01-21\",\"2021-01-22\",\"2021-01-25\",\"2021-01-26\",\"2021-01-27\",\"2021-01-28\",\"2021-01-29\",\"2021-02-01\",\"2021-02-02\",\"2021-02-03\",\"2021-02-04\",\"2021-02-05\",\"2021-02-08\",\"2021-02-09\",\"2021-02-10\",\"2021-02-11\",\"2021-02-12\",\"2021-02-16\",\"2021-02-17\",\"2021-02-18\",\"2021-02-19\",\"2021-02-22\",\"2021-02-23\",\"2021-02-24\",\"2021-02-25\",\"2021-02-26\",\"2021-03-01\",\"2021-03-02\",\"2021-03-03\",\"2021-03-04\",\"2021-03-05\",\"2021-03-08\",\"2021-03-09\",\"2021-03-10\",\"2021-03-11\",\"2021-03-12\",\"2021-03-15\",\"2021-03-16\",\"2021-03-17\",\"2021-03-18\",\"2021-03-19\",\"2021-03-22\",\"2021-03-23\",\"2021-03-24\",\"2021-03-25\",\"2021-03-26\",\"2021-03-29\",\"2021-03-30\",\"2021-03-31\",\"2021-04-01\",\"2021-04-05\",\"2021-04-06\",\"2021-04-07\",\"2021-04-08\",\"2021-04-09\",\"2021-04-12\",\"2021-04-13\",\"2021-04-14\",\"2021-04-15\",\"2021-04-16\",\"2021-04-19\",\"2021-04-20\",\"2021-04-21\",\"2021-04-22\",\"2021-04-23\",\"2021-04-26\",\"2021-04-27\",\"2021-04-28\",\"2021-04-29\",\"2021-04-30\",\"2021-05-03\",\"2021-05-04\",\"2021-05-05\",\"2021-05-06\",\"2021-05-07\",\"2021-05-10\",\"2021-05-11\",\"2021-05-12\",\"2021-05-13\",\"2021-05-14\",\"2021-05-17\",\"2021-05-18\",\"2021-05-19\",\"2021-05-20\",\"2021-05-21\",\"2021-05-24\",\"2021-05-25\",\"2021-05-26\",\"2021-05-27\",\"2021-05-28\",\"2021-06-01\",\"2021-06-02\",\"2021-06-03\",\"2021-06-04\",\"2021-06-07\",\"2021-06-08\",\"2021-06-09\",\"2021-06-10\",\"2021-06-11\",\"2021-06-14\",\"2021-06-15\",\"2021-06-16\",\"2021-06-17\",\"2021-06-18\",\"2021-06-21\",\"2021-06-22\",\"2021-06-23\",\"2021-06-24\",\"2021-06-25\",\"2021-06-28\",\"2021-06-29\",\"2021-06-30\",\"2021-07-01\",\"2021-07-02\",\"2021-07-06\",\"2021-07-07\",\"2021-07-08\",\"2021-07-09\",\"2021-07-12\",\"2021-07-13\",\"2021-07-14\",\"2021-07-15\",\"2021-07-16\",\"2021-07-19\",\"2021-07-20\",\"2021-07-21\",\"2021-07-22\",\"2021-07-23\",\"2021-07-26\",\"2021-07-27\",\"2021-07-28\",\"2021-07-29\",\"2021-07-30\",\"2021-08-02\",\"2021-08-03\",\"2021-08-04\",\"2021-08-05\",\"2021-08-06\",\"2021-08-09\",\"2021-08-10\",\"2021-08-11\",\"2021-08-12\",\"2021-08-13\",\"2021-08-16\",\"2021-08-17\",\"2021-08-18\",\"2021-08-19\",\"2021-08-20\",\"2021-08-23\",\"2021-08-24\",\"2021-08-25\",\"2021-08-26\",\"2021-08-27\",\"2021-08-30\",\"2021-08-31\",\"2021-09-01\",\"2021-09-02\",\"2021-09-03\",\"2021-09-07\"],\"type\":\"candlestick\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"rangeslider\":{\"visible\":true}},\"title\":{\"text\":\"Apple Stock Price Analysis\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f21fc384-bfbf-4fc9-880a-5520dac3763d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3MfpKFpH9bm",
        "outputId": "f1f43180-84eb-48b3-b215-7632a6f99c6f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Open      High       Low     Close  Adj Close    Volume\n",
            "Open       1.000000  0.994551  0.993183  0.986214   0.986177 -0.466338\n",
            "High       0.994551  1.000000  0.992951  0.993586   0.993307 -0.440815\n",
            "Low        0.993183  0.992951  1.000000  0.993915   0.994187 -0.517327\n",
            "Close      0.986214  0.993586  0.993915  1.000000   0.999899 -0.489407\n",
            "Adj Close  0.986177  0.993307  0.994187  0.999899   1.000000 -0.493779\n",
            "Volume    -0.466338 -0.440815 -0.517327 -0.489407  -0.493779  1.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-23236a4e6045>:1: FutureWarning:\n",
            "\n",
            "The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Autots"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ervdjH0IE0U",
        "outputId": "baf53d82-2df6-49cd-8d71-f11ed74702cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Autots in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from Autots) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from Autots) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from Autots) (0.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from Autots) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->Autots) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->Autots) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->Autots) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->Autots) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->Autots) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.10.0->Autots) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.10.0->Autots) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.10.0->Autots) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from autots import AutoTS\n",
        "model = AutoTS(forecast_length=5, frequency='infer', ensemble='simple')\n",
        "model = model.fit(df, date_col='Date', value_col='Close', id_col=None)\n",
        "prediction = model.predict()\n",
        "forecast = prediction.forecast\n",
        "print(forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs5jRf7QIXjp",
        "outputId": "c2e14224-9fd8-4674-e340-5fca8b347e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data frequency is: B, used frequency is: B\n",
            "Model Number: 1 with model ARIMA in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 8 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 10s 6ms/step - loss: 0.3966\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3874\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3845\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3752\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3681\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3681\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3599\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3611\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3591\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3491\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3449\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3408\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3325\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3219\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3194\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3171\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3137\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3086\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3085\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3047\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3007\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2931\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2950\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2900\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2963\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2789\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2841\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2819\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2701\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2686\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2783\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2669\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2528\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2556\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2602\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2661\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2562\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2501\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2393\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2395\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2327\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2407\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2234\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2188\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2104\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2167\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2063\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1995\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1884\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1941\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "Model Number: 10 with model ETS in generation 0 of 10\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLM in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n",
            "Model Number: 14 with model GLS in generation 0 of 10\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
            "Model Number: 19 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
            "Model Number: 31 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
            "Model Number: 33 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
            "Model Number: 34 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 35 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 36 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/3wxrtyew.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/i1nevklm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64443', 'data', 'file=/tmp/tmpfe0z3f0s/3wxrtyew.json', 'init=/tmp/tmpfe0z3f0s/i1nevklm.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelvwxfw5rx/prophet_model-20230924181131.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:11:31 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:11:31 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 37 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 39 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 39 in generation 0: MultivariateRegression\n",
            "Model Number: 40 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 40 in generation 0: DatepartRegression\n",
            "Model Number: 41 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 42 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 44 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 45 with model ETS in generation 0 of 10\n",
            "Model Number: 46 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
            "Model Number: 47 with model ARDL in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 49 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 53 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 54 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 55 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/7qwpwa3s.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/mmb727n3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63004', 'data', 'file=/tmp/tmpfe0z3f0s/7qwpwa3s.json', 'init=/tmp/tmpfe0z3f0s/mmb727n3.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model84j043cm/prophet_model-20230924181133.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:11:33 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:11:33 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 56 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 57 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 58 with model NVAR in generation 0 of 10\n",
            "Model Number: 59 with model Theta in generation 0 of 10\n",
            "Model Number: 60 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
            "Model Number: 61 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
            "Model Number: 62 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 63 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 64 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLS in generation 0 of 10\n",
            "Model Number: 66 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 67 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
            "Model Number: 68 with model ETS in generation 0 of 10\n",
            "Model Number: 69 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning:\n",
            "\n",
            "Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1406: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+02, tolerance: 4.031e-02\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/oxxwti8m.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/5kjes20s.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=73942', 'data', 'file=/tmp/tmpfe0z3f0s/oxxwti8m.json', 'init=/tmp/tmpfe0z3f0s/5kjes20s.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model6del8m_9/prophet_model-20230924181135.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:11:35 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:11:35 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 70 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
            "Model Number: 71 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 72 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
            "Model Number: 73 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
            "Model Number: 74 with model ARIMA in generation 0 of 10\n",
            "Model Number: 75 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 76 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 77 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 77 in generation 0: UnivariateRegression\n",
            "Model Number: 78 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 78 in generation 0: MultivariateRegression\n",
            "Model Number: 79 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 80 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 81 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
            "Model Number: 82 with model NVAR in generation 0 of 10\n",
            "Model Number: 83 with model Theta in generation 0 of 10\n",
            "Model Number: 84 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 84 in generation 0: ARDL\n",
            "Model Number: 85 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
            "Model Number: 86 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 87 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 88 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 89 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 90 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 91 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 91 in generation 0: ARDL\n",
            "Model Number: 92 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 93 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 94 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 95 with model ARDL in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 96 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/5hvrhfyq.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/tevvs51k.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=93320', 'data', 'file=/tmp/tmpfe0z3f0s/5hvrhfyq.json', 'init=/tmp/tmpfe0z3f0s/tevvs51k.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modeledmqg9ty/prophet_model-20230924181142.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:11:42 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:11:42 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 97 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 98 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 99 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 100 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 101 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
            "Model Number: 102 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 103 with model Theta in generation 0 of 10\n",
            "Model Number: 104 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning:\n",
            "\n",
            "One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
            "Model Number: 105 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 105 in generation 0: GLM\n",
            "Model Number: 106 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
            "Model Number: 107 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 108 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 109 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
            "Model Number: 110 with model ETS in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
            "Model Number: 111 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 112 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
            "Model Number: 113 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 114 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 115 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 116 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
            "Model Number: 117 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
            "Model Number: 118 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 118 in generation 0: GLM\n",
            "Model Number: 119 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 120 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 121 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning:\n",
            "\n",
            "Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1406: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 122 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
            "Model Number: 123 with model GLS in generation 0 of 10\n",
            "Model Number: 124 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
            "Model Number: 125 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 126 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 127 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
            "Model Number: 128 with model GLS in generation 0 of 10\n",
            "Model Number: 129 with model Theta in generation 0 of 10\n",
            "Model Number: 130 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 131 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
            "Model Number: 132 with model NVAR in generation 0 of 10\n",
            "Model Number: 133 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 134 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 135 with model GLS in generation 0 of 10\n",
            "Model Number: 136 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 137 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
            "Model Number: 138 with model WindowRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 7s 30ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 1s 37ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 36ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 1s 32ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 2s 52ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 2s 49ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 1s 32ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 1s 32ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 1s 32ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 1s 30ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 1s 31ms/step - loss: nan\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Model Number: 139 with model GLM in generation 0 of 10\n",
            "Model Number: 140 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 141 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
            "Model Number: 142 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 143 with model GLS in generation 0 of 10\n",
            "Model Number: 144 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 144 in generation 0: DatepartRegression\n",
            "Model Number: 145 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
            "Model Number: 146 with model Theta in generation 0 of 10\n",
            "Model Number: 147 with model ETS in generation 0 of 10\n",
            "Model Number: 148 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 149 with model ARDL in generation 0 of 10\n",
            "Model Number: 150 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 151 with model VAR in generation 0 of 10\n",
            "Model Number: 152 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 153 with model Theta in generation 0 of 10\n",
            "Model Number: 154 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 155 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 155 in generation 0: DatepartRegression\n",
            "Model Number: 156 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 156 in generation 0: GLM\n",
            "Model Number: 157 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
            "Model Number: 158 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
            "Model Number: 159 with model NVAR in generation 0 of 10\n",
            "Model Number: 160 with model GLS in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/wf2x29je.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/jqd42tah.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=83659', 'data', 'file=/tmp/tmpfe0z3f0s/wf2x29je.json', 'init=/tmp/tmpfe0z3f0s/jqd42tah.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model8hhkq6se/prophet_model-20230924181319.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:19 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 161 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 161 in generation 0: SectionalMotif\n",
            "Model Number: 162 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:13:19 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 163 with model ETS in generation 0 of 10\n",
            "Model Number: 164 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
            "Model Number: 165 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 166 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
            "Model Number: 167 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 167 in generation 0: ARIMA\n",
            "Model Number: 168 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 169 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 170 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
            "Model Number: 171 with model Theta in generation 0 of 10\n",
            "Model Number: 172 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 173 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 174 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 175 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 176 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 176 in generation 0: ARDL\n",
            "Model Number: 177 with model GLS in generation 0 of 10\n",
            "Model Number: 178 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 179 with model ARDL in generation 0 of 10\n",
            "Model Number: 180 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 181 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
            "Model Number: 182 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 183 with model ARIMA in generation 0 of 10\n",
            "Model Number: 184 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 184 in generation 0: DatepartRegression\n",
            "Model Number: 185 with model ETS in generation 0 of 10\n",
            "Model Number: 186 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
            "New Generation: 1 of 10\n",
            "Model Number: 187 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 188 with model Theta in generation 1 of 10\n",
            "Model Number: 189 with model UnivariateMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 189 in generation 1: UnivariateMotif\n",
            "Model Number: 190 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 191 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 192 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 193 with model ARIMA in generation 1 of 10\n",
            "Model Number: 194 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 195 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 196 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 197 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 198 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/1g2bdwrb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/pw9m9shg.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=27145', 'data', 'file=/tmp/tmpfe0z3f0s/1g2bdwrb.json', 'init=/tmp/tmpfe0z3f0s/pw9m9shg.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modeleoxo_jrw/prophet_model-20230924181325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:13:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 199 with model GLS in generation 1 of 10\n",
            "Model Number: 200 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 201 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 202 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 203 with model Theta in generation 1 of 10\n",
            "Model Number: 204 with model NVAR in generation 1 of 10\n",
            "Model Number: 205 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 206 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 207 with model NVAR in generation 1 of 10\n",
            "Model Number: 208 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 209 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 210 with model ARDL in generation 1 of 10\n",
            "Model Number: 211 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 212 with model ConstantNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 213 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 214 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 215 with model ETS in generation 1 of 10\n",
            "Model Number: 216 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 217 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 218 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 218 in generation 1: ARIMA\n",
            "Model Number: 219 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/hwmhe10n.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/tokqx5g8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63734', 'data', 'file=/tmp/tmpfe0z3f0s/hwmhe10n.json', 'init=/tmp/tmpfe0z3f0s/tokqx5g8.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modellhk0v1ss/prophet_model-20230924181331.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:31 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:13:31 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 220 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 221 with model ETS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 222 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/sucrzpc6.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/i61crlae.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=49786', 'data', 'file=/tmp/tmpfe0z3f0s/sucrzpc6.json', 'init=/tmp/tmpfe0z3f0s/i61crlae.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelh8x7nkzx/prophet_model-20230924181332.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:32 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:13:32 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 223 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 224 with model GLS in generation 1 of 10\n",
            "Model Number: 225 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 226 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 227 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 228 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 229 with model ARDL in generation 1 of 10\n",
            "Model Number: 230 with model ConstantNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/7ylflla_.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 231 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/ilo0jw8_.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=54506', 'data', 'file=/tmp/tmpfe0z3f0s/7ylflla_.json', 'init=/tmp/tmpfe0z3f0s/ilo0jw8_.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelr7utha6t/prophet_model-20230924181333.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:33 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:13:33 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 232 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 233 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 234 with model Theta in generation 1 of 10\n",
            "Model Number: 235 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 236 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 237 with model Theta in generation 1 of 10\n",
            "Model Number: 238 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 239 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 240 with model MultivariateMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 240 in generation 1: MultivariateMotif\n",
            "Model Number: 241 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 242 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 243 with model VAR in generation 1 of 10\n",
            "Model Number: 244 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 245 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 246 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 246 in generation 1: ARIMA\n",
            "Model Number: 247 with model ETS in generation 1 of 10\n",
            "Model Number: 248 with model VAR in generation 1 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 248 in generation 1: VAR\n",
            "Model Number: 249 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 250 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 251 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 252 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 253 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 254 with model ARIMA in generation 1 of 10\n",
            "Model Number: 255 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 256 with model NVAR in generation 1 of 10\n",
            "Model Number: 257 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 258 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/44arfcoz.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/vvvs1m8y.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41923', 'data', 'file=/tmp/tmpfe0z3f0s/44arfcoz.json', 'init=/tmp/tmpfe0z3f0s/vvvs1m8y.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelomjr62vn/prophet_model-20230924181346.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:13:46 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:13:46 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 259 with model ARDL in generation 1 of 10\n",
            "Model Number: 260 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 261 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 262 with model NVAR in generation 1 of 10\n",
            "Model Number: 263 with model Theta in generation 1 of 10\n",
            "Model Number: 264 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 265 with model ETS in generation 1 of 10\n",
            "Model Number: 266 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 267 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 268 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 269 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 270 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series Close failed with error IndexError('tuple index out of range') exog train None and predict None\") in model 270 in generation 1: ARDL\n",
            "Model Number: 271 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 271 in generation 1: MultivariateRegression\n",
            "Model Number: 272 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 273 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 274 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 275 with model GLS in generation 1 of 10\n",
            "Model Number: 276 with model ETS in generation 1 of 10\n",
            "Model Number: 277 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 278 with model ARIMA in generation 1 of 10\n",
            "Model Number: 279 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 280 with model NVAR in generation 1 of 10\n",
            "Model Number: 281 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 282 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series Close failed with error IndexError('tuple index out of range') exog train None and predict None\") in model 282 in generation 1: ARDL\n",
            "Model Number: 283 with model NVAR in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/thresholding.py:204: RuntimeWarning:\n",
            "\n",
            "overflow encountered in double_scalars\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 284 with model ARDL in generation 1 of 10\n",
            "Model Number: 285 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 286 with model Theta in generation 1 of 10\n",
            "Model Number: 287 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 288 with model ETS in generation 1 of 10\n",
            "Model Number: 289 with model FBProphet in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 289 in generation 1: FBProphet\n",
            "Model Number: 290 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 291 with model VAR in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 291 in generation 1: VAR\n",
            "Model Number: 292 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 293 with model NVAR in generation 1 of 10\n",
            "Model Number: 294 with model Theta in generation 1 of 10\n",
            "Model Number: 295 with model NVAR in generation 1 of 10\n",
            "Model Number: 296 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 297 with model GLS in generation 1 of 10\n",
            "Model Number: 298 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 299 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 5s 5ms/step - loss: 0.0961\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0372\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0377\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0306\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0321\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0307\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0287\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0286\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0286\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0278\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0285\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0286\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0274\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0272\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0259\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0265\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0264\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0252\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0248\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0252\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0238\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0241\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0236\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0249\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0231\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0231\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0217\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0215\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0203\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0187\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0191\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0205\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0192\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0199\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0179\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0199\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0188\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0192\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0186\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0180\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 300 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 301 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 302 with model LastValueNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/d4j1t108.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/l50dbrat.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=33389', 'data', 'file=/tmp/tmpfe0z3f0s/d4j1t108.json', 'init=/tmp/tmpfe0z3f0s/l50dbrat.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modellvgkq8it/prophet_model-20230924181403.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "18:14:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 303 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:14:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 304 with model ETS in generation 1 of 10\n",
            "Model Number: 305 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 306 with model ARIMA in generation 1 of 10\n",
            "Model Number: 307 with model WindowRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - 7s 39ms/step - loss: 0.9952\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 1s 47ms/step - loss: 0.7750\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.7721\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.7699\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 1s 50ms/step - loss: 0.7662\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.7597\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7546\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7537\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7512\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.7499\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7451\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7386\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7379\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.7347\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7319\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7279\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7267\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 0.7232\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7189\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7203\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7161\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7106\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7081\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.7093\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 0.7060\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 0.7009\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6985\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.6999\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.6941\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.6918\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.6898\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.6886\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.6844\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6825\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6813\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6768\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 0.6759\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6738\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.6678\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6680\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6690\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6646\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6609\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6595\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.6599\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6513\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6543\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.6505\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.6485\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.6477\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model Number: 308 with model WindowRegression in generation 1 of 10\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000053 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Model Number: 309 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 310 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 311 with model WindowRegression in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 312 with model ARDL in generation 2 of 10\n",
            "Model Number: 313 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 314 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/3_qdv4u3.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/uzo55m7y.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3793', 'data', 'file=/tmp/tmpfe0z3f0s/3_qdv4u3.json', 'init=/tmp/tmpfe0z3f0s/uzo55m7y.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelln66rmou/prophet_model-20230924181447.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:14:47 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:14:47 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 315 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 316 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 317 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 318 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 319 with model NVAR in generation 2 of 10\n",
            "Model Number: 320 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 320 in generation 2: FBProphet\n",
            "Model Number: 321 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 321 in generation 2: DatepartRegression\n",
            "Model Number: 322 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 323 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/o3y7q3yy.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/a5j7e0i4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=6365', 'data', 'file=/tmp/tmpfe0z3f0s/o3y7q3yy.json', 'init=/tmp/tmpfe0z3f0s/a5j7e0i4.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modely68i7np4/prophet_model-20230924181448.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:14:48 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:14:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 324 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 325 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 326 with model GLS in generation 2 of 10\n",
            "Model Number: 327 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 327 in generation 2: WindowRegression\n",
            "Model Number: 328 with model NVAR in generation 2 of 10\n",
            "Model Number: 329 with model AverageValueNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 329 in generation 2: AverageValueNaive\n",
            "Model Number: 330 with model ARDL in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series Close failed with error IndexError('tuple index out of range') exog train None and predict None\") in model 330 in generation 2: ARDL\n",
            "Model Number: 331 with model NVAR in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in divide\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 332 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 333 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 334 with model ARDL in generation 2 of 10\n",
            "Model Number: 335 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 335 in generation 2: FBProphet\n",
            "Model Number: 336 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 337 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 338 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 339 with model UnivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 339 in generation 2: UnivariateRegression\n",
            "Model Number: 340 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 341 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 342 with model VAR in generation 2 of 10\n",
            "Model Number: 343 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 344 with model ETS in generation 2 of 10\n",
            "Model Number: 345 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 345 in generation 2: WindowRegression\n",
            "Model Number: 346 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 347 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 348 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 349 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 350 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 351 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 352 with model ARIMA in generation 2 of 10\n",
            "Model Number: 353 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 354 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 355 with model ETS in generation 2 of 10\n",
            "Model Number: 356 with model GLS in generation 2 of 10\n",
            "Model Number: 357 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 358 with model NVAR in generation 2 of 10\n",
            "Model Number: 359 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in divide\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 360 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 361 with model GLS in generation 2 of 10\n",
            "Model Number: 362 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 363 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 364 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 365 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 366 with model Theta in generation 2 of 10\n",
            "Model Number: 367 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 367 in generation 2: UnobservedComponents\n",
            "Model Number: 368 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 369 with model SeasonalNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 369 in generation 2: SeasonalNaive\n",
            "Model Number: 370 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 371 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 372 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 372 in generation 2: UnobservedComponents\n",
            "Model Number: 373 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 374 with model ARDL in generation 2 of 10\n",
            "Model Number: 375 with model Theta in generation 2 of 10\n",
            "Model Number: 376 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 377 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 378 with model GLS in generation 2 of 10\n",
            "Model Number: 379 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 380 with model NVAR in generation 2 of 10\n",
            "Model Number: 381 with model WindowRegression in generation 2 of 10\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Model Number: 382 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 383 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 5s 6ms/step - loss: 1.6155\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6131\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6119\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6125\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6077\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6098\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6033\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6009\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5991\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5961\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5942\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5911\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5788\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5829\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5593\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5654\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5487\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5315\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5378\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5431\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5299\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5221\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5285\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4868\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4356\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4371\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4777\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4285\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4270\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4135\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4442\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4619\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4438\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4224\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4389\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4342\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3924\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4328\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3851\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4121\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3612\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3701\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4335\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4288\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4004\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4395\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3637\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3540\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3223\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2951\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/koly2ruu.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/55gleea8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=59678', 'data', 'file=/tmp/tmpfe0z3f0s/koly2ruu.json', 'init=/tmp/tmpfe0z3f0s/55gleea8.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelgtaa90fv/prophet_model-20230924181507.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:15:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:15:07 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 384 with model FBProphet in generation 2 of 10\n",
            "Model Number: 385 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 385 in generation 2: FBProphet\n",
            "Model Number: 386 with model GLM in generation 2 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 386 in generation 2: GLM\n",
            "Model Number: 387 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 388 with model ARIMA in generation 2 of 10\n",
            "Model Number: 389 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 390 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 390 in generation 2: UnobservedComponents\n",
            "Model Number: 391 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 392 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 393 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 394 with model Theta in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 394 in generation 2: Theta\n",
            "Model Number: 395 with model GLS in generation 2 of 10\n",
            "Model Number: 396 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 396 in generation 2: ETS\n",
            "Model Number: 397 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 398 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 399 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 400 with model ARDL in generation 2 of 10\n",
            "Model Number: 401 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 401 in generation 2: MultivariateRegression\n",
            "Model Number: 402 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 403 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 404 with model Theta in generation 2 of 10\n",
            "Model Number: 405 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 406 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 407 with model LastValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/vg6jgvab.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/_ci7l7fu.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=70805', 'data', 'file=/tmp/tmpfe0z3f0s/vg6jgvab.json', 'init=/tmp/tmpfe0z3f0s/_ci7l7fu.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modeldry3yu8_/prophet_model-20230924181511.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:15:11 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 408 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:15:11 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 409 with model VAR in generation 2 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 409 in generation 2: VAR\n",
            "Model Number: 410 with model ARIMA in generation 2 of 10\n",
            "Model Number: 411 with model NVAR in generation 2 of 10\n",
            "Model Number: 412 with model ARDL in generation 2 of 10\n",
            "Model Number: 413 with model WindowRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/6opj2yfo.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/v71n_hbs.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=76163', 'data', 'file=/tmp/tmpfe0z3f0s/6opj2yfo.json', 'init=/tmp/tmpfe0z3f0s/v71n_hbs.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model0jne5uwy/prophet_model-20230924181541.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:15:41 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 414 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:15:41 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 415 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 416 with model Theta in generation 2 of 10\n",
            "Model Number: 417 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 418 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 419 with model Theta in generation 2 of 10\n",
            "Model Number: 420 with model Theta in generation 2 of 10\n",
            "Model Number: 421 with model ARIMA in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 421 in generation 2: ARIMA\n",
            "Model Number: 422 with model ARIMA in generation 2 of 10\n",
            "Model Number: 423 with model ETS in generation 2 of 10\n",
            "Model Number: 424 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 425 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 426 with model NVAR in generation 2 of 10\n",
            "Model Number: 427 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 427 in generation 2: FBProphet\n",
            "Model Number: 428 with model GLS in generation 2 of 10\n",
            "Model Number: 429 with model ARDL in generation 2 of 10\n",
            "Model Number: 430 with model VAR in generation 2 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 430 in generation 2: VAR\n",
            "Model Number: 431 with model ARIMA in generation 2 of 10\n",
            "Model Number: 432 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 433 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 434 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 435 with model NVAR in generation 2 of 10\n",
            "Model Number: 436 with model ETS in generation 2 of 10\n",
            "New Generation: 3 of 10\n",
            "Model Number: 437 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 437 in generation 3: FBProphet\n",
            "Model Number: 438 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 438 in generation 3: MultivariateRegression\n",
            "Model Number: 439 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 440 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 441 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 442 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/0pgh72gz.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/xcdtje37.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=71451', 'data', 'file=/tmp/tmpfe0z3f0s/0pgh72gz.json', 'init=/tmp/tmpfe0z3f0s/xcdtje37.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model8u_80svl/prophet_model-20230924181602.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:16:02 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:16:02 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 443 with model ARIMA in generation 3 of 10\n",
            "Model Number: 444 with model VAR in generation 3 of 10\n",
            "Model Number: 445 with model ARIMA in generation 3 of 10\n",
            "Model Number: 446 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 446 in generation 3: DatepartRegression\n",
            "Model Number: 447 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 448 with model GLS in generation 3 of 10\n",
            "Model Number: 449 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/47qkjzx0.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/r797yc0o.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=43585', 'data', 'file=/tmp/tmpfe0z3f0s/47qkjzx0.json', 'init=/tmp/tmpfe0z3f0s/r797yc0o.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modelqzkyiapx/prophet_model-20230924181607.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:16:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:16:08 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 450 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 451 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 452 with model NVAR in generation 3 of 10\n",
            "Model Number: 453 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 453 in generation 3: UnivariateRegression\n",
            "Model Number: 454 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 455 with model ETS in generation 3 of 10\n",
            "Model Number: 456 with model ARIMA in generation 3 of 10\n",
            "Model Number: 457 with model VAR in generation 3 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 457 in generation 3: VAR\n",
            "Model Number: 458 with model ARDL in generation 3 of 10\n",
            "Model Number: 459 with model NVAR in generation 3 of 10\n",
            "Model Number: 460 with model NVAR in generation 3 of 10\n",
            "Model Number: 461 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 462 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/k35z6qum.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/5i4sz95i.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=2378', 'data', 'file=/tmp/tmpfe0z3f0s/k35z6qum.json', 'init=/tmp/tmpfe0z3f0s/5i4sz95i.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_modeln3nf_v0f/prophet_model-20230924181612.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:16:12 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:16:12 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 463 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 464 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 465 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 466 with model ARDL in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 466 in generation 3: ARDL\n",
            "Model Number: 467 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 467 in generation 3: WindowRegression\n",
            "Model Number: 468 with model ARDL in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning:\n",
            "\n",
            "Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning:\n",
            "\n",
            "Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 469 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 470 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 470 in generation 3: FBProphet\n",
            "Model Number: 471 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 472 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 473 with model NVAR in generation 3 of 10\n",
            "Model Number: 474 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 475 with model ARDL in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 475 in generation 3: ARDL\n",
            "Model Number: 476 with model AverageValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 476 in generation 3: AverageValueNaive\n",
            "Model Number: 477 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning:\n",
            "\n",
            "Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 478 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 479 with model NVAR in generation 3 of 10\n",
            "Model Number: 480 with model ARIMA in generation 3 of 10\n",
            "Model Number: 481 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 482 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 483 with model MultivariateMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/596ftfxn.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfe0z3f0s/a7dpxwmw.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=53692', 'data', 'file=/tmp/tmpfe0z3f0s/596ftfxn.json', 'init=/tmp/tmpfe0z3f0s/a7dpxwmw.json', 'output', 'file=/tmp/tmpfe0z3f0s/prophet_model5xpemfvj/prophet_model-20230924181625.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:16:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 484 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:16:26 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 485 with model NVAR in generation 3 of 10\n",
            "Model Number: 486 with model Theta in generation 3 of 10\n",
            "Model Number: 487 with model VAR in generation 3 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 487 in generation 3: VAR\n",
            "Model Number: 488 with model ARDL in generation 3 of 10\n"
          ]
        }
      ]
    }
  ]
}